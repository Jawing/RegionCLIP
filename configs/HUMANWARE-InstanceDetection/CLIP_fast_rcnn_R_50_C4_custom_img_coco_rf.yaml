_BASE_: "./CLIP_fast_rcnn_R_50_C4_ovd.yaml"
MODEL:
  MASK_ON: False
  ROI_HEADS:
    NUM_CLASSES: 5
    NMS_THRESH_TEST: 0.1 #Defaults to 0.5
    SCORE_THRESH_TEST: 0.5 #Defaults to 0.001
    # SOFT_NMS_ENABLED: True
  CLIP:
    #set no box delta to see original RPN proposal location
    NO_BOX_DELTA: False #set to True only detecting OOD class or for zero-shot (model aren't trained on those class), set false improves detection on base classes (box delta realigns prediction coordinates based on learned class head)
    OFFLINE_RPN_NMS_THRESH: 0.7 #default 0.9 for custom or zsinf
    # MULTIPLY_RPN_SCORE: True #uncomment for >100% scores with objectiveness logits
    # TODO see if VIS affects region features generation
    VIS: True # Note: visualize the scores before multiplying RPN scores, if any
    #set true below for RPN region features
    BG_CLS_SCORE: False #generate all rpn bbox and scores include background bboxes and scores
    OFFLINE_RPN_PRE_NMS_TOPK_TEST: 12000 #default 6000
    OFFLINE_RPN_POST_NMS_TOPK_TEST: 2000 #default 1000
    CLS_ID_NMS: True #default False
    MULTIPLY_RPN_SCORE: False #note true can give >100% scores with objectiveness logits, RPN and head score interact 
    CROP_REGION_TYPE: "RPN" #default "RPN" can switch to GT with NO_BOX_DELTA
  # doesn't register use above
  # RPN:
  #   NMS_THRESH: 0.7
  #   PRE_NMS_TOPK_TEST: 12000 #default 6000
  #   POST_NMS_TOPK_TEST: 2000 #default 1000
DATASETS:
  TRAIN: ("humanware_train_full",)
  # TEST: ("humanware_test_custom",)
  # TEST: ("humanware_test_basic",)
  # TEST: ("humanware_test_collected",)
  # TEST: ("humanware_test_full",)
  TEST: ("humanware_test_awake",)
  # TEST: ("lvis_v1_val_custom_img",)  #custom images for lvis dataset
TEST:
  DETECTIONS_PER_IMAGE: 100 #set equal POST_NMS_TOPK_TEST to detect all from RPN


